{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Item-based collaborative filtering рекомендательная система\n",
    "##### HR@10  0.092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Games RSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# импорты, которые точно понадобятся\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Данные взяты отсюда - http://jmcauley.ucsd.edu/data/amazon/\n",
    "# http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_5.json.gz\n",
    "JSON_DATA_PATH = \"./reviews_Video_Games_5.json\"\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def iter_json_data(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            yield data\n",
    "            \n",
    "def get_data_frame():\n",
    "    uid_to_id = {}\n",
    "    iid_to_id = {}\n",
    "    \n",
    "    cols = [\"uid\", \"iid\", \"review\", \"rating\", \"dt\"]\n",
    "    rows = []\n",
    "    for d in iter_json_data(JSON_DATA_PATH):\n",
    "        uid = uid_to_id.setdefault(d[\"reviewerID\"], len(uid_to_id))\n",
    "        iid = iid_to_id.setdefault(d[\"asin\"], len(iid_to_id))\n",
    "        review = d[\"reviewText\"]\n",
    "        rating = float(d[\"overall\"])\n",
    "        dt = int(d[\"unixReviewTime\"])\n",
    "        rows.append((uid, iid, review, rating, dt))\n",
    "        \n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 112 ms, total: 2.29 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_df_by_dt(df, p=0.8):\n",
    "    \"\"\"Функция разбивает df на тестовую и тренировочную выборки по времени \n",
    "    публикации отзывов (значение времени в поле dt)\n",
    "    \n",
    "    :param p: персентиль значений dt, которые образуют тренировочную выборку. Например p=0.8 означает, что в \n",
    "    тренировочной части будут отзывы, соответствующие первым 80% временного интервала \n",
    "    :return: два pd.DataFrame объекта\n",
    "    \"\"\"\n",
    "    border_dt = df.dt.quantile(p)\n",
    "    print(\"Min=%s, border=%s, max=%s\" % (df.dt.min(), border_dt, df.dt.max()))\n",
    "    training_df, test_df  = df[df.dt <= border_dt], df[df.dt > border_dt]\n",
    "    print(\"Размер до очистки:\", training_df.shape, test_df.shape)\n",
    "    # удаляем из тестовых данных строки, соответствующие пользователям или объектам, \n",
    "    # которых нет в тренировочных данных \n",
    "    # (пользователи - избегаем проблем для персональных систем, объекты - для всех)\n",
    "    test_df = test_df[test_df.uid.isin(training_df.uid) & test_df.iid.isin(training_df.iid)]\n",
    "    print(\"Размер после очистки:\", training_df.shape, test_df.shape)\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min=939859200, border=1377129600.0, max=1405987200\n",
      "Размер до очистки: (185427, 5) (46353, 5)\n",
      "Размер после очистки: (185427, 5) (19174, 5)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = split_df_by_dt(df)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hit_ratio(recs_dict, test_dict):\n",
    "    \"\"\"Функция считает метрику hit-ration для двух словарей\n",
    "    :recs_dict: словарь рекомендаций типа {uid: {iid: score, ...}, ...}\n",
    "    :test_dict: тестовый словарь типа {uid: {iid: score, ...}, ...}\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for uid in test_dict:\n",
    "        if set(test_dict[uid].keys()).intersection(recs_dict.get(uid, {})):\n",
    "            hits += 1\n",
    "    return hits / len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_dict(test_df):\n",
    "    \"\"\"Функция, конвертирующая тестовый df в словарь\n",
    "    \"\"\"\n",
    "    test_dict = {}\n",
    "    for t in test_df.itertuples():\n",
    "        test_dict.setdefault(t.uid, {})\n",
    "        test_dict[t.uid][t.iid] = t.rating\n",
    "    return test_dict\n",
    "\n",
    "test_dict = get_test_dict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ItemBased Top-K Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class BasicRecommender(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        \"\"\"Строит рекомендации для пользователя uid\n",
    "        :return: словарь типа {iid: score, ...}\n",
    "        \"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        \"\"\"Строит рекомендации для нескольких пользователей uids\n",
    "        :return: словарь типа {uid: {iid: score, ...}, ...}\n",
    "        \"\"\"\n",
    "        return {uid: self.get_recs(uid, top) for uid in uids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "def load_data(df):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    \n",
    "    uid_to_row = {}\n",
    "    iid_to_col = {}\n",
    "    \n",
    "    mean_ratings=df.groupby(df.uid).rating.mean()\n",
    "    \n",
    "    for t in df.itertuples():\n",
    "        row_id = uid_to_row.setdefault(t.uid, len(uid_to_row))\n",
    "        col_id = iid_to_col.setdefault(t.iid, len(iid_to_col))\n",
    "        rating = t.rating\n",
    "        \n",
    "        rows.append(row_id)\n",
    "        cols.append(col_id)\n",
    "        data.append(1.0) #игнорируем рейтинги\n",
    "        \n",
    "    ui_m = csr_matrix((data, (rows, cols)))\n",
    "    return ui_m, uid_to_row, iid_to_col\n",
    "#########################################################################\n",
    "# вспомогательные функции, которые могут пригодиться при построении Item-based CF\n",
    "def nullify_main_diagonal(m):\n",
    "    positions = range(m.shape[0])\n",
    "    eye = csr_matrix((np.ones(len(positions)), (positions, positions)), m.shape)\n",
    "    return m - m.multiply(eye)\n",
    "def get_topk(matrix, top, axis=1):\n",
    "    \"\"\"Converts source matrix to Top-K matrix\n",
    "    where each row or column contains only top K values\n",
    "\n",
    "    :param matrix: source matrix\n",
    "    :param top: number of top items to be stored\n",
    "    :param axis: 0 - top by column, 1 - top by row\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    if axis == 0:\n",
    "        matrix = matrix.T.tocsr()\n",
    "\n",
    "    for row_id, row in enumerate(matrix):\n",
    "        if top is not None and row.nnz > top:\n",
    "            top_args = np.argsort(row.data)[-top:]\n",
    "\n",
    "            rows += [row_id] * top\n",
    "            cols += row.indices[top_args].tolist()\n",
    "            data += row.data[top_args].tolist()\n",
    "        elif row.nnz > 0:\n",
    "            rows += [row_id] * row.nnz\n",
    "            cols += row.indices.tolist()\n",
    "            data += row.data.tolist()\n",
    "\n",
    "    topk_m = csr_matrix((data, (rows, cols)), (matrix.shape[0], matrix.shape[1]))\n",
    "\n",
    "    if axis == 0:\n",
    "        topk_m = topk_m.T.tocsr()\n",
    "\n",
    "    return topk_m\n",
    "######################################################################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "\n",
    "class ItemBasedTopKRecommender(BasicRecommender):\n",
    "    def __init__(self,TOPK=30,verbose=0):\n",
    "        super(BasicRecommender, self).__init__()\n",
    "        self.TOPK=TOPK\n",
    "        self.verbose=verbose\n",
    "    def fit(self,training_df):\n",
    "\n",
    "        self.log(\"fit on %d records\"%(len(training_df)))\n",
    "        start=time.time()\n",
    "        self.ui_m, self.uid_to_row, self.iid_to_col = load_data(training_df)\n",
    "        self.col_to_iid = {col_id: iid for iid, col_id in self.iid_to_col.items()}\n",
    "        self.log(\"load_data(): %0.1f sec\"%(time.time()-start))\n",
    "        \n",
    "        \n",
    "        #Построение sim-матрицы\n",
    "        start=time.time()\n",
    "        self.ii_sim_m = cosine_similarity(self.ui_m.T.tocsr(), dense_output=False)\n",
    "        self.ii_sim_m = nullify_main_diagonal(self.ii_sim_m)\n",
    "        #оставляем в строках и столбцах только Top-K компонент\n",
    "        self.ii_sim_m = get_topk(self.ii_sim_m, top=self.TOPK,axis=1)\n",
    "        self.ii_sim_m = get_topk(self.ii_sim_m, top=self.TOPK,axis=0)                \n",
    "        #нормализуем матрицу\n",
    "        self.ii_sim_m_norm=csr_matrix(normalize(self.ii_sim_m,axis=1))\n",
    "        self.log(\"build sim matrix: %0.1f sec\"%(time.time()-start))\n",
    "             \n",
    "        #Создаем словарик user-item чтобы в дальнейшем не рекомендовать уже купленные игры\n",
    "        self.used_items=dict()\n",
    "        for t in training_df.itertuples():\n",
    "            self.used_items[(t.uid,t.iid)]=True\n",
    "    \n",
    "    def get_recs(self, uid, top=N):\n",
    "        recs = []\n",
    "        if uid in self.uid_to_row:\n",
    "            u_row_id = self.uid_to_row[uid]\n",
    "            u_row = self.ui_m[u_row_id]\n",
    "\n",
    "            predicted_prob=self.ii_sim_m_norm.dot(u_row.T).T.tocsr()  #/u_row.sum()\n",
    "            top_args = np.argsort(-predicted_prob.data)\n",
    "\n",
    "            for arg_id in top_args:\n",
    "                if len(recs)>=top:\n",
    "                    #если уже набралось N рекомендаций, на выход!\n",
    "                    break\n",
    "                col_id = predicted_prob.indices[arg_id]\n",
    "                iid=self.col_to_iid[col_id]\n",
    "                if not ((uid,iid) in self.used_items):\n",
    "                    #пропускаем уже купленные мгры\n",
    "                    score = predicted_prob.data[arg_id]\n",
    "                    recs.append((iid,score))\n",
    "        return recs\n",
    "    def log(self,msg):\n",
    "        if self.verbose>0:\n",
    "            print(msg,flush=True)\n",
    "    \n",
    "    def get_batch_recs(self, uids, top=N):\n",
    "        rez=dict()\n",
    "        self.log(\"Get recommendations: \")        \n",
    "        it=uids\n",
    "        if self.verbose:\n",
    "            it=tqdm(it)\n",
    "        \n",
    "        for uid in it:\n",
    "            rez[uid]=dict(self.get_recs(uid,top)[:top])\n",
    "        return rez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальный тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit on 185427 records\n",
      "load_data(): 0.3 sec\n",
      "build sim matrix: 1.5 sec\n",
      "Get recommendations: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6815/6815 [00:06<00:00, 1124.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR:  0.09200293470286133\n",
      "CPU times: user 8.06 s, sys: 32 ms, total: 8.1 s\n",
      "Wall time: 8.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommender=ItemBasedTopKRecommender(verbose=True)\n",
    "recommender.fit(training_df)\n",
    "recs_dict=recommender.get_batch_recs(test_df.uid.unique())\n",
    "value=hit_ratio(recs_dict,test_dict)   \n",
    "print(\"HR: \",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR:  0.09200293470286133\n"
     ]
    }
   ],
   "source": [
    "print(\"HR: \",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
